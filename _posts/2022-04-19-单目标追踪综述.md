---
layout: post
title:  "单目标追踪综述"
date:   2022-04-19
blurb: "A look at an example post using Bay Jekyll theme."
og_image: /assets/img/content/post-example/Banner.jpg
---

<img src="{{ "/assets/blog/2022-04-19/TrackingNet.PNG" | absolute_url }}" alt="TrackingNet" class="post-pic"/>

图1. 单目标追踪示意图。图片来自数据集[TrackingNet](https://tracking-net.org/).

<br />

## 1. 任务介绍

单目标追踪的输入是一个视频序列，在第一帧中给定目标的检测框，而后在视频中实现对该目标的追踪。相比于多目标追踪，单目标追踪的优势主要在于 1）一般计算量较小，适用于终端设备，2）追踪目标可以任意，无需预先设定。其在军事领域(如弹头制导)、体育娱乐(如抖音人机互动)、生产应用(如大疆无人机跟拍)等领域有着重要应用价值。

## 2. 主要难点

* **目标形变**。目标的尺寸变化(由远及近)、或是角度变化(正面到侧面)。目标的形变 1）一方面提高了对特征鲁棒性的要求，2）一方面提高了目标框预测的要求，使其能适应不断变化的目标外形。

* **目标消失重现**。目标由于遮挡、或出视野，造成目标消失后重现。这一问题的主要难点在于，1)如何判断目标的消失，及时停止目标模型的更新； 2) 对再出现的目标进行重识别与追踪。目标的重识别（或重检测）不仅需要在较大甚至全图区域进行目标的检索；更困难的是，要利用非常有限的信息（第一帧的标注信息和准确性存疑的追踪结果），在可能存在大量相似的目标内实现对追踪目标的准确识别。

* **相似目标的区分**。如在篮球场中追踪某一运动员，该问题的主要挑战在于，一个通用的追踪模型很难直接区分细类(ID级别)的目标。如何在追踪的过程中更新目标特征，提升特征的区分性，区分同类其他目标，是该问题的核心难点。

* **相机运动或目标快速运动**。由于相机抖动或目标快速移动，会使目标出搜索区域，导致追踪失效。如何高效更新搜索区域，使目标始终在搜索区域中，是该问题的一个有效解决方案。

综上来看，单目标追踪的关键技术主要有以下几点：

1. 目标表征
2. 搜索策略
3. 模型更新方法
4. 针对不同情况的特殊策略

接下来，我将结合方法框架和上述几个关键技术点，展开对单目标追踪的方法综述。

## 3. 问题描述

给定一个长度为$ T $的视频序列$ \mathcal{I}=\\{\mathbf{I}_1,...,\mathbf{I}_T\\} $, 和一个初始目标框 $ \mathbf{G} $。用$\mathcal{y}_t= \\{\mathbf{b}_t,\mathbf{o_t}\\} $代表第$t$帧目标的状态变量，其中，$\mathbf{b}_t\in \mathbb{R}^{1\times 4}$ 代表目标的边界框，$o_t\in \\{0,1\\}$代表目标出现与否。用$\mathcal{Y}=\\{\mathcal{y}_1,...,\mathcal{y}_T\\}$代表整个视频序列$\mathcal{I}$的追踪结果。那么，单目标追踪就可以描述为：

$$\underset{\mathcal{Y}}{\mathrm{argmax}}~~~P(~\mathcal{Y}~|~\mathcal{I},\mathbf{G})$$


即给定序列$\mathcal{I}$和初始目标框$\mathbf{G}$，估计目标在每一时刻$t$的状态$\mathcal{y}_t$。

## 4. 方法介绍
<img src="{{ "/assets/blog/2022-04-19/develop_tree.png" | absolute_url }}" alt="bay" class="post-pic"/>

单目标追踪算法演化树，图片来自[Visual Tracking Paper List](https://github.com/foolwood/benchmark_results#visual-tracking-paper-list).

目前单目标追踪方法的分类多种多样。为梳理清单目标追踪方法的演变及目前主流的追踪方法，本文将根据单目标方法的演化历史，挑选一些关键的方法进行介绍。


1. [基于相关滤波](#4.1-基于相关滤波)
    * CF
    * MOSSE
        * CSK
            * KCF
            * SRDCF
            * C-COT
            * ECO
        * MCCF
            * BACF
2. [基于深度学习](#4.2-基于深度学习)
    * SiameseFC
        * SiamRPN
        * 
    * ATOM
        * DiMP

    * MDNet

3. [其他](#4.3-其他)


## 4.1 基于相关滤波

### 4.1.1 Correlation Filter (CF)
<img src="{{ "/assets/blog/2022-04-19/CF.PNG" | absolute_url }}" alt="bay" class="post-pic"/>
图2. 相关滤波流程图。图片来自参考资料[4]。

相关滤波(Correlation Filter)的原理就是，卷积的输出代表两个输入信号f和g的相关性。相关性越高，响应越强。相关性越低，响应越弱。将上述思想应用于单目标追踪任务，我们用给定目标的模板特征（信号f）去卷积新输入图片的特征（信号g），得到一个响应图（Response Map）。响应最大的地方，就是给定目标在新输入图片的出现位置。这就是CF做单目标追踪的核心思想。为降低计算复杂度，一般都通过快速傅里叶变化（Fast Fourier Transform, FFT）将输入图像特征转换到频域，而后在频域进行矩阵内积，得到的结果再通过逆傅里叶变换（IFFT）得到响应图。

图2展示了一般CF追踪的框架图。第一步， 特征提取。在初始阶段，根据给定的目标框进行抠图，提取目标的特征图$\mathbf{F}$。而后，对于新输入的图片进行特征提取，并使用Cosine window对输入特征进行滤波（缓解边界效应），得到输入图像的特征图$\mathbf{G}$。第二步，响应图计算。分别对特征图$\mathbf{F}$和$\mathbf{G}$进行FFT，得到相应的频域特征图$\mathbf{F}^* $和$\mathbf{G}^* $。在频域对他们进行矩阵点积，得到频域的响应图 $\mathbf{R}^* $:

$$\mathbf{R}^*=\mathbf{F}^*\odot \mathbf{G}^*, $$

并对$\mathbf{R}^* $进行IFFT，得到响应图$\mathbf{R}$。 第三步，目标定位与滤波器更新。响应图$\mathbf{R}$的峰值位置就代表着目标的位置。而后，通过设计ground-truth响应图（对应图中desired output,一般为2D高斯分布，最大值位置为目标位置），用$\mathbf{D}$代表。并结合图像特征$\mathbf{G}$，实现目标特征$\mathbf{F}$的更新：

$$\mathbf{F}^*_{update} =\frac{\mathbf{D}^*}{\mathbf{G}^*},$$

该处为element-wise矩阵除。

<br />

### 4.1.2 MOSSE: Visual object tracking using adaptive correlation filters

MOSSE (Minimizing Sum of Squared Error) 使用灰度图像作为输入。相比于CF的主要改进在于，假定目标可以出现在任何位置（而不是在正中间）并使用多个训练样本进行训练。目标函数可写为：

$$\underset{\mathbf{F}^*}{\mathrm{min}}~~~\underset{i}{\sum} | \mathbf{F}^*\odot \mathbf{G}^*_i - \mathbf{D}^*_i|,$$

其中，$\mathbf{G}^*_i,\mathbf{D}$分别为输入图片特征、ground-truth的FFT变换。

上式的解可写为：

$$\mathbf{F}^*_{update}=\frac{\sum_i \mathbf{D}^*_i\odot \overline{\mathbf{G}^*_i}}{\sum_i \mathbf{G}^*_i\odot \overline{\mathbf{G}^*_i}},$$

其中，分子为输入图片特征和ground-truth的相关滤波，分母为输入图片特征的energy spectrum。

<br />

### 4.1.3 CSK: Exploiting the Circulant Structure of Tracking-by-Detection with Kernels

<img src="{{ "/assets/blog/2022-04-19/CSK_densesampling.png" | absolute_url }}" alt="CSK densesampling" class="post-pic"/>

CSK相比于MOSSE的主要改进在于：
* 使用密集采样替代随机采样，并利用循环矩阵提高计算效率
* 利用核技巧，提出核函数最小二乘求解法(kernel regularized least square solution)

#### 1）核函数最小二乘法

具体来说，CSK在目标框周边密集采集一圈目标图片$(x_1,y_1),...,(x_m,y_m)$，而后用这些带标签的样本训练线性分类器$f(x)=<w,x>+b$:

$$\underset{\mathbf{w},b}{min} \sum_{i=1}^m L(y_i, f(x_i))+\lambda \lVert \mathbf{w}\rVert,$$

其中，$y_i$为类别标签，$\lVert \mathbf{w}\rVert$为正则项。$L(y,f(x))=max(0,1-yf(x))$为岭回归(ridge loss)。利用核函数特性，对上式求解，解为输入特征在核空间的线性组合$\mathbf{w}=\sum_i \alpha_i \varphi(x_i)$。对应的权重向量$\mathbf{\alpha}$求解方法为:

$$\mathbf{\alpha}=(K+\lambda I)^{-1}\mathbf{y},$$

其中，$K$为核矩阵，每一元素$K_{i,j}=k(x_i,x_j)$, $I$为单位矩阵，$\mathbf{y}$的每一元素为$y_i$。即核函数最小二乘法。

#### 2）密集采样和循环矩阵

我们用$C(\mathbf{u})$代表一个向量$\mathbf{u}$的循环移位矩阵：

<img src="{{ "/assets/blog/2022-04-19/CSK_Cu.png" | absolute_url }}" alt="CSK C(u)" class="post-pic"/>

其有如下性质：

<img src="{{ "/assets/blog/2022-04-19/CSK_circulant.png" | absolute_url }}" alt="CSK circulant" class="post-pic" div align=center/>

即，如果我们按顺序对目标进行密集均匀采样后，这些样本可以拼接成一个循环矩阵。这个循环矩阵和另一个样本的相似性，可以直接在频域内进行点积计算得到。利用上述性质，我们给定一个模板$z$和一个搜索区域$x$，$z$在这片区域的密集相应可以写为：

$$\mathbf{y}=\mathcal{F}^{-1}(\mathcal{F}(\mathbf{k})\odot \mathcal{F}(\mathbf{\alpha})),$$

其中，$\mathbf{k}$的每一元素$\mathbf{k}_i=k(\mathbf{z},P^i\mathbf{x})$。上式表明如何计算目标在一个区域内的密集响应。

### 4.2 基于深度学习


### 4.3 其他



## 参考资料

1. [Benchmarking the State-of-th-Art in Visual Tracking](file:///E:/Study/Mendeley/task/tracking/SOT/VALSE_tracking_yi-wu.pdf). 吴毅，2014.10.15 <br />
2. Javed, S., Danelljan, M., Khan, F. S., Khan, M. H., Felsberg, M., & Matas, J. (2021). Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook. arXiv preprint arXiv:2112.02838. <br />
3. Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: A survey. Acm computing surveys (CSUR), 38(4), 13-es. <br />
4. You, S., Zhu, H., Li, M., & Li, Y. (2019). A review of visual trackers and analysis of its application to mobile robot. arXiv preprint arXiv:1910.09761. <br />