---
layout: post
title:  "单目标追踪综述"
date:   2021-04-19
blurb: "A look at an example post using Bay Jekyll theme."
og_image: /assets/img/content/post-example/Banner.jpg
---

<img src="{{ "/assets/blog/2022-04-19/TrackingNet.png" | absolute_url }}" alt="TrackingNet" class="post-pic"/>

图1. 单目标追踪示意图。图片来自数据集[TrackingNet](https://tracking-net.org/).

<br />

### 1. 任务介绍

单目标追踪的输入是一个视频序列，在第一帧中给定目标的检测框，而后在视频中实现对该目标的追踪。相比于多目标追踪，单目标追踪的优势主要在于 1）一般计算量较小，适用于终端设备，2）追踪目标可以任意，无需预先设定。其在军事领域(如弹头制导)、体育娱乐(如抖音人机互动)、生产应用(如大疆无人机跟拍)等领域有着重要应用价值。

### 2. 主要难点

* **目标形变**。目标的尺寸变化(由远及近)、或是角度变化(正面到侧面)。目标的形变 1）一方面提高了对特征鲁棒性的要求，2）一方面提高了目标框预测的要求，使其能适应不断变化的目标外形。

* **目标消失重现**。目标由于遮挡、或出视野，造成目标消失后重现。这一问题的主要难点在于，1)如何判断目标的消失，及时停止目标模型的更新； 2) 对再出现的目标进行重识别与追踪。目标的重识别（或重检测）不仅需要在较大甚至全图区域进行目标的检索；更困难的是，要利用非常有限的信息（第一帧的标注信息和准确性存疑的追踪结果），在可能存在大量相似的目标内实现对追踪目标的准确识别。

* **相似目标的区分**。如在篮球场中追踪某一运动员，该问题的主要挑战在于，一个通用的追踪模型很难直接区分细类(ID级别)的目标。如何在追踪的过程中更新目标特征，提升特征的区分性，区分同类其他目标，是该问题的核心难点。

* **相机运动或目标快速运动**。由于相机抖动或目标快速移动，会使目标出搜索区域，导致追踪失效。如何高效更新搜索区域，使目标始终在搜索区域中，是该问题的一个有效解决方案。

综上来看，单目标追踪的关键技术主要有以下几点：

1. 目标表征
2. 搜索策略
3. 模型更新方法
4. 针对不同情况的特殊策略

接下来，我将结合方法框架和上述几个关键技术点，展开对单目标追踪的方法综述。

### 3. 问题描述

给定一个长度为$ T $的视频序列$ \mathcal{I}=\\{\mathbf{I}_1,...,\mathbf{I}_T\\} $, 和一个初始目标框 $ \mathbf{G} $。用$\mathcal{y}_t= \\{\mathbf{b}_t,\mathbf{o_t}\\} $代表第$t$帧目标的状态变量，其中，$\mathbf{b}_t\in \mathbb{R}^{1\times 4}$ 代表目标的边界框，$o_t\in \\{0,1\\}$代表目标出现与否。用$\mathcal{Y}=\\{\mathcal{y}_1,...,\mathcal{y}_T\\}$代表整个视频序列$\mathcal{I}$的追踪结果。那么，单目标追踪就可以描述为：

$$
\underset{\mathcal{Y}}{\mathrm{argmax}}~~~P(~\mathcal{Y}~|~\mathcal{I},\mathbf{G})
$$

即给定序列$\mathcal{I}$和初始目标框$\mathbf{G}$，估计目标在每一时刻$t$的状态$\mathcal{y}_t$。

### 4. 方法介绍
<img src="{{ "/assets/blog/2022-04-19/develop_tree.png" | absolute_url }}" alt="bay" class="post-pic"/>

单目标追踪算法演化树，图片来自[Visual Tracking Paper List](https://github.com/foolwood/benchmark_results#visual-tracking-paper-list).

目前单目标追踪方法的分类多种多样。为梳理清单目标追踪方法的演变及目前主流的追踪方法，本文将根据单目标方法的演化历史，挑选一些关键的方法进行介绍。


1. [基于相关滤波](#4.1-基于相关滤波)
    * CF
    * MOSSE
        * CSK
            * KCF
            * SRDCF
            * C-COT
            * ECO
        * MCCF
            * BACF
2. [基于深度学习](#4.2-基于深度学习)
    * SiameseFC
        * SiamRPN
        * 
    * ATOM
        * DiMP

    * MDNet

3. [其他](#4.3-其他)


#### 4.1 基于相关滤波

#### 4.1.1 Correlation Filter (CF)
<img src="{{ "/assets/blog/2022-04-19/CF.png" | absolute_url }}" alt="bay" class="post-pic"/>
图2. 相关滤波流程图。图片来自参考资料[4]。

相关滤波(Correlation Filter)的原理就是，卷积的输出代表两个输入信号f和g的相关性。相关性越高，响应越强。相关性越低，响应越弱。将上述思想应用于单目标追踪任务，我们用给定目标的模板特征（信号f）去卷积新输入图片的特征（信号g），得到一个响应图（Response Map）。响应最大的地方，就是给定目标在新输入图片的出现位置。这就是CF做单目标追踪的核心思想。为降低计算复杂度，一般都通过快速傅里叶变化（Fast Fourier Transform, FFT）将输入图像特征转换到频域，而后在频域进行矩阵内积，得到的结果再通过逆傅里叶变换（IFFT）得到响应图。

图2展示了一般CF追踪的框架图。第一步， 特征提取。在初始阶段，根据给定的目标框进行抠图，提取目标的特征图$\mathbf{F}$。而后，对于新输入的图片进行特征提取，并使用Cosine window对输入特征进行滤波（缓解边界效应），得到输入图像的特征图$\mathbf{G}$。第二步，响应图计算。分别对特征图$\mathbf{F}$和$\mathbf{G}$进行FFT，得到相应的频域特征图$\mathbf{F}^* $和$\mathbf{G}^* $。在频域对他们进行矩阵点积，得到频域的响应图 $\mathbf{R}^* $:

$$\mathbf{R}^*=\mathbf{F}^*\odot \mathbf{G}^*, $$

并对$\mathbf{R}^* $进行IFFT，得到响应图$\mathbf{R}$。 和第三步，目标定位与滤波器更新。响应图$\mathbf{R}$的峰值位置就代表着目标的位置。而后，通过设计ground-truth响应图（对应图中desired output,一般为2D高斯分布，最大值位置为目标位置），用$\mathbf{D}$代表。并结合图像特征$\mathbf{G}$，实现目标特征$\mathbf{F}$的更新：

$$\mathbf{F}^*_{update} =\mathbf{D}^*\oslash \mathbf{G}^*, $$

$\oslash$代表element-wise矩阵除。



#### 4.2 基于深度学习


#### 4.3 其他



### 参考资料

1. [Benchmarking the State-of-th-Art in Visual Tracking](file:///E:/Study/Mendeley/task/tracking/SOT/VALSE_tracking_yi-wu.pdf). 吴毅，2014.10.15 <br />
2. Javed, S., Danelljan, M., Khan, F. S., Khan, M. H., Felsberg, M., & Matas, J. (2021). Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook. arXiv preprint arXiv:2112.02838. <br />
3. Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: A survey. Acm computing surveys (CSUR), 38(4), 13-es. <br />
4. You, S., Zhu, H., Li, M., & Li, Y. (2019). A review of visual trackers and analysis of its application to mobile robot. arXiv preprint arXiv:1910.09761. <br />